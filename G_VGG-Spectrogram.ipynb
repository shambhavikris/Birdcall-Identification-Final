{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each TF-Record file is for a single class and will be loaded into a separate tf.data.Dataset\n",
    "# these datasets will be appended to a list, and fed into tf.experimental.sample_from_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6573,
     "status": "ok",
     "timestamp": 1599628819633,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "Luj86eVFt7bN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pathlib\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6558,
     "status": "ok",
     "timestamp": 1599628819635,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "zKLgUBXOuEdK"
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 264 \n",
    "SAMPLE_RATE = 30000 # Audio sample rate\n",
    "MAX_DURATION = 30 # Clip duration in seconds \n",
    "FFT_SIZE = 1024 # Fourier Transform size \n",
    "HOP_SIZE = 512 # Number of samples between each successive FFT window\n",
    "N_MEL_BINS = 128 \n",
    "N_SPECTROGRAM_BINS = (FFT_SIZE // 2) + 1\n",
    "F_MIN = 20 # Min frequency cutoff\n",
    "F_MAX = SAMPLE_RATE / 2  # Max Frequency cutoff\n",
    "BATCH_SIZE = 4  # Training Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7772,
     "status": "ok",
     "timestamp": 1599628820858,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "7hFRs66suIWE"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/content/drive/My Drive/train.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7765,
     "status": "ok",
     "timestamp": 1599628820859,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "vNBbZJNTuMAZ"
   },
   "outputs": [],
   "source": [
    "# directories for Train and Test TF Records, 264 files in each\n",
    "train_dir = '/content/drive/My Drive/lala1/Data/Train'\n",
    "test_dir = '/content/drive/My Drive/lala1/Data/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook uses 30 seconds worth of data at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12258,
     "status": "ok",
     "timestamp": 1599628825358,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "Rj2rUhd6uNdf"
   },
   "outputs": [],
   "source": [
    "train_tfr = os.listdir(train_dir)\n",
    "test_tfr = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12252,
     "status": "ok",
     "timestamp": 1599628825360,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "gv5MprK5uPC4"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "          'feature0': tf.io.FixedLenFeature((), tf.string),\n",
    "          'feature1': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "\n",
    "    feature0 = tf.io.parse_tensor(example['feature0'], out_type = tf.float32)\n",
    "    feature1 = example['feature1']\n",
    "\n",
    "    return feature0, feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19975,
     "status": "ok",
     "timestamp": 1599628833088,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "JehtVoS6uQdI"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "lis = [0]*264\n",
    "for d in train_tfr:\n",
    "    d_path = os.path.join(train_dir, d)\n",
    "    tfrecord_dataset_train = tf.data.TFRecordDataset([d_path], compression_type=\"GZIP\")\n",
    "    dataset = tfrecord_dataset_train.map(read_tfrecord)\n",
    "    lis[i] = dataset\n",
    "    i = i+1\n",
    "\n",
    "train_ds = tf.data.experimental.sample_from_datasets(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22843,
     "status": "ok",
     "timestamp": 1599628835962,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "uEE4RRRyuSa6"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "lis = [0]*264\n",
    "for d in test_tfr:\n",
    "    d_path = os.path.join(test_dir, d)\n",
    "    tfrecord_dataset_test = tf.data.TFRecordDataset([d_path], compression_type=\"GZIP\")\n",
    "    dataset = tfrecord_dataset_test.map(read_tfrecord)\n",
    "    lis[i] = dataset\n",
    "    i = i+1\n",
    "\n",
    "test_ds = tf.data.experimental.sample_from_datasets(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22841,
     "status": "ok",
     "timestamp": 1599628835968,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "pSeLcUDVuUGn"
   },
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, shuffle_buffer_size=64, batch_size=6):\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.batch(batch_size).repeat()\n",
    "    ds = ds.map(setshape)\n",
    "    ds = ds.prefetch(5)\n",
    "    return ds\n",
    "\n",
    "def setshape(x, y):\n",
    "    x.set_shape([None, 900000,1])\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y.set_shape([None,1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22835,
     "status": "ok",
     "timestamp": 1599628835968,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "Kje10nxluV1t"
   },
   "outputs": [],
   "source": [
    "train_final = prepare_for_training(train_ds)\n",
    "test_final = prepare_for_training(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding tensors to a layer which calculated the Mel Spectrogram for the given audio instance\n",
    "# this in turn is treated like an image, and 2D convolutions are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22829,
     "status": "ok",
     "timestamp": 1599628835969,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "CcXL9I4euXfx"
   },
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting feature extractor from trained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24083,
     "status": "ok",
     "timestamp": 1599628837228,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "EdrqFKBKueWM",
    "outputId": "0f030318-3d78-416d-b2e0-99c389fa7575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "trained_vgg = tf.keras.applications.VGG16(include_top=False)\n",
    "feature_extractor_layer = trained_vgg.get_layer('block3_conv3')\n",
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24075,
     "status": "ok",
     "timestamp": 1599628837228,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "w9QMLsJAvdD1",
    "outputId": "c67277dc-a124-4549-d91e-0632ba5559bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,124,608\n",
      "Non-trainable params: 590,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trained_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24066,
     "status": "ok",
     "timestamp": 1599628837229,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "-WxMxRQJvDcv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D)\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def ConvModel(n_classes, sample_rate=SAMPLE_RATE, duration=MAX_DURATION,\n",
    "              fft_size=FFT_SIZE, hop_size=HOP_SIZE, n_mels=N_MEL_BINS, fmin=F_MIN, fmax=F_MAX):\n",
    "    n_samples = sample_rate * duration\n",
    "    input_shape = (n_samples,)\n",
    "\n",
    "    x = Input(shape=input_shape, name='input', dtype='float32')    \n",
    "    y = LogMelSpectrogram(sample_rate, fft_size, hop_size, n_mels, fmin, fmax)(x)\n",
    "    y = BatchNormalization(axis=2)(y)\n",
    "\n",
    "\n",
    "    y = Conv2D(3, (3,3), padding='same')(y)  \n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = trained_vgg(y, training=False)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = Dense(1024, activation='relu')(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    y = Dense(512, activation='relu')(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    \n",
    "    y = Dense(n_classes, activation='softmax')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24058,
     "status": "ok",
     "timestamp": 1599628837229,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "4ud9q744wlJr",
    "outputId": "5505d948-4824-421b-ee67-a41eebda4e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 900000)]          0         \n",
      "_________________________________________________________________\n",
      "log_mel_spectrogram (LogMelS (None, 1756, 128, 1)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1756, 128, 1)      512       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1756, 128, 3)      30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1756, 128, 3)      12        \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              113247232 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 264)               135432    \n",
      "=================================================================\n",
      "Total params: 128,622,706\n",
      "Trainable params: 128,032,364\n",
      "Non-trainable params: 590,342\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, schedules\n",
    "\n",
    "n_classes = N_CLASSES\n",
    "model = ConvModel(n_classes)\n",
    "\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.05, decay_steps=1000, decay_rate=0.96, staircase=False\n",
    ")\n",
    "sgd = SGD(learning_rate=lr_schedule, momentum=0.85)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24045,
     "status": "ok",
     "timestamp": 1599628837229,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "N4qAfovmwnno",
    "outputId": "c0761554-0d6d-4692-c523-d067d0c40013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5343"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train)//BATCH_SIZE\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "oVj2nvCtx5oq",
    "outputId": "67e571a4-7472-49dc-c4b8-d72f2cb6cbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 4.9373 - sparse_categorical_accuracy: 0.0417\n",
      "Epoch 00001: val_loss improved from inf to 6.41932, saving model to /content/drive/My Drive/Bird/VGG/VGG-one\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one/assets\n",
      "5343/5343 [==============================] - 3166s 593ms/step - loss: 4.9373 - sparse_categorical_accuracy: 0.0417 - val_loss: 6.4193 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 3.8803 - sparse_categorical_accuracy: 0.1572\n",
      "Epoch 00002: val_loss improved from 6.41932 to 4.86148, saving model to /content/drive/My Drive/Bird/VGG/VGG-one\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one/assets\n",
      "5343/5343 [==============================] - 2868s 537ms/step - loss: 3.8803 - sparse_categorical_accuracy: 0.1572 - val_loss: 4.8615 - val_sparse_categorical_accuracy: 0.0833\n",
      "Epoch 3/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 2.7864 - sparse_categorical_accuracy: 0.3496\n",
      "Epoch 00003: val_loss improved from 4.86148 to 4.81677, saving model to /content/drive/My Drive/Bird/VGG/VGG-one\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one/assets\n",
      "5343/5343 [==============================] - 2833s 530ms/step - loss: 2.7864 - sparse_categorical_accuracy: 0.3496 - val_loss: 4.8168 - val_sparse_categorical_accuracy: 0.1667\n",
      "Epoch 4/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 2.0547 - sparse_categorical_accuracy: 0.4968\n",
      "Epoch 00004: val_loss improved from 4.81677 to 4.40919, saving model to /content/drive/My Drive/Bird/VGG/VGG-one\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one/assets\n",
      "5343/5343 [==============================] - 2774s 519ms/step - loss: 2.0547 - sparse_categorical_accuracy: 0.4968 - val_loss: 4.4092 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 5/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 1.5459 - sparse_categorical_accuracy: 0.6116\n",
      "Epoch 00005: val_loss did not improve from 4.40919\n",
      "5343/5343 [==============================] - 2809s 526ms/step - loss: 1.5459 - sparse_categorical_accuracy: 0.6116 - val_loss: 5.3793 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 6/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 1.1782 - sparse_categorical_accuracy: 0.6944\n",
      "Epoch 00006: val_loss improved from 4.40919 to 2.59099, saving model to /content/drive/My Drive/Bird/VGG/VGG-one\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one/assets\n",
      "5343/5343 [==============================] - 2838s 531ms/step - loss: 1.1782 - sparse_categorical_accuracy: 0.6944 - val_loss: 2.5910 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 7/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.8354 - sparse_categorical_accuracy: 0.7773\n",
      "Epoch 00007: val_loss did not improve from 2.59099\n",
      "5343/5343 [==============================] - 2815s 527ms/step - loss: 0.8354 - sparse_categorical_accuracy: 0.7773 - val_loss: 2.5948 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 8/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.6323 - sparse_categorical_accuracy: 0.8305\n",
      "Epoch 00008: val_loss did not improve from 2.59099\n",
      "5343/5343 [==============================] - 2779s 520ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.8305 - val_loss: 2.6526 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.4764 - sparse_categorical_accuracy: 0.8698\n",
      "Epoch 00009: val_loss did not improve from 2.59099\n",
      "5343/5343 [==============================] - 2473s 463ms/step - loss: 0.4764 - sparse_categorical_accuracy: 0.8698 - val_loss: 6.0383 - val_sparse_categorical_accuracy: 0.0833\n",
      "Epoch 10/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.3693 - sparse_categorical_accuracy: 0.8999\n",
      "Epoch 00010: val_loss did not improve from 2.59099\n",
      "5343/5343 [==============================] - 2822s 528ms/step - loss: 0.3693 - sparse_categorical_accuracy: 0.8999 - val_loss: 4.4968 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 11/20\n",
      " 741/5343 [===>..........................] - ETA: 34:05 - loss: 0.2695 - sparse_categorical_accuracy: 0.9217Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = 'Model-5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    verbose=2)\n",
    "\n",
    "model.fit(train_final, \n",
    "          epochs=20, \n",
    "          steps_per_epoch=steps_per_epoch, \n",
    "          validation_data=test_final, \n",
    "          validation_steps=2, \n",
    "          callbacks=[model_checkpoint_callback])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOwNn5o1LEv6kHDIZCp5ivu",
   "mount_file_id": "1CfPHjtRcy71w29djt8g8Hsq1G81BXeon",
   "name": "VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
