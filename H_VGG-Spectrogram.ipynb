{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each TF-Record file is for a single class and will be loaded into a separate tf.data.Dataset\n",
    "# these datasets will be appended to a list, and fed into tf.experimental.sample_from_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6842,
     "status": "ok",
     "timestamp": 1600059059610,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "Luj86eVFt7bN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pathlib\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1362,
     "status": "ok",
     "timestamp": 1600059100061,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "zKLgUBXOuEdK"
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 264 \n",
    "SAMPLE_RATE = 30000 # Audio sample rate\n",
    "MAX_DURATION = 30 # Clip duration in seconds \n",
    "FFT_SIZE = 1024 # Fourier Transform size \n",
    "HOP_SIZE = 512 # Number of samples between each successive FFT window\n",
    "N_MEL_BINS = 128 \n",
    "N_SPECTROGRAM_BINS = (FFT_SIZE // 2) + 1\n",
    "F_MIN = 20 # Min frequency cutoff\n",
    "F_MAX = SAMPLE_RATE / 2  # Max Frequency cutoff\n",
    "BATCH_SIZE = 12  # Training Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1739,
     "status": "ok",
     "timestamp": 1600059100443,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "7hFRs66suIWE"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/content/drive/My Drive/train.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1353,
     "status": "ok",
     "timestamp": 1600059100444,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "vNBbZJNTuMAZ"
   },
   "outputs": [],
   "source": [
    "# directories for Train and Test TF Records, 264 files in each\n",
    "train_dir = '/content/drive/My Drive/lala1/Data/Train'\n",
    "test_dir = '/content/drive/My Drive/lala1/Data/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook uses 30 seconds worth of data at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4582,
     "status": "ok",
     "timestamp": 1600059104022,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "Rj2rUhd6uNdf"
   },
   "outputs": [],
   "source": [
    "train_tfr = os.listdir(train_dir)\n",
    "test_tfr = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2569,
     "status": "ok",
     "timestamp": 1600059104023,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "gv5MprK5uPC4"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "          'feature0': tf.io.FixedLenFeature((), tf.string),\n",
    "          'feature1': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "\n",
    "    feature0 = tf.io.parse_tensor(example['feature0'], out_type = tf.float32)\n",
    "    feature1 = example['feature1']\n",
    "\n",
    "    return feature0, feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10158,
     "status": "ok",
     "timestamp": 1600059112622,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "JehtVoS6uQdI"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "lis = [0]*264\n",
    "for d in train_tfr:\n",
    "    d_path = os.path.join(train_dir, d)\n",
    "    tfrecord_dataset_train = tf.data.TFRecordDataset([d_path], compression_type=\"GZIP\")\n",
    "    dataset = tfrecord_dataset_train.map(read_tfrecord)\n",
    "    lis[i] = dataset\n",
    "    i = i+1\n",
    "\n",
    "train_ds = tf.data.experimental.sample_from_datasets(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12673,
     "status": "ok",
     "timestamp": 1600059115594,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "uEE4RRRyuSa6"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "lis = [0]*264\n",
    "for d in test_tfr:\n",
    "    d_path = os.path.join(test_dir, d)\n",
    "    tfrecord_dataset_test = tf.data.TFRecordDataset([d_path], compression_type=\"GZIP\")\n",
    "    dataset = tfrecord_dataset_test.map(read_tfrecord)\n",
    "    lis[i] = dataset\n",
    "    i = i+1\n",
    "\n",
    "test_ds = tf.data.experimental.sample_from_datasets(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12203,
     "status": "ok",
     "timestamp": 1600059115596,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "pSeLcUDVuUGn"
   },
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, shuffle_buffer_size=64, batch_size=BATCH_SIZE):\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.batch(batch_size).repeat()\n",
    "    ds = ds.map(setshape)\n",
    "    ds = ds.prefetch(5)\n",
    "    return ds\n",
    "\n",
    "def setshape(x, y):\n",
    "    x.set_shape([None, 900000,1])\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y.set_shape([None,1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1600059116752,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "Kje10nxluV1t"
   },
   "outputs": [],
   "source": [
    "train_final = prepare_for_training(train_ds)\n",
    "test_final = prepare_for_training(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding tensors to a layer which calculated the Mel Spectrogram for the given audio instance\n",
    "# this in turn is treated like an image, and 2D convolutions are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21552,
     "status": "ok",
     "timestamp": 1599825409678,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "CcXL9I4euXfx"
   },
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting feature extractor from trained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22148,
     "status": "ok",
     "timestamp": 1599825410289,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "EdrqFKBKueWM",
    "outputId": "e2096986-4c75-4c82-fa5d-527697b67098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "trained_vgg = tf.keras.applications.VGG16(include_top=False)\n",
    "feature_extractor_layer = trained_vgg.get_layer('block3_conv3')\n",
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22976,
     "status": "ok",
     "timestamp": 1599825411126,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "w9QMLsJAvdD1",
    "outputId": "0fd63d22-e172-406c-ad5b-96f9f72abd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,124,608\n",
      "Non-trainable params: 590,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trained_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22975,
     "status": "ok",
     "timestamp": 1599825411127,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "-WxMxRQJvDcv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D)\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def ConvModel(n_classes, sample_rate=SAMPLE_RATE, duration=MAX_DURATION,\n",
    "              fft_size=FFT_SIZE, hop_size=HOP_SIZE, n_mels=N_MEL_BINS, fmin=F_MIN, fmax=F_MAX):\n",
    "    n_samples = sample_rate * duration\n",
    "    input_shape = (n_samples,)\n",
    "\n",
    "    x = Input(shape=input_shape, name='input', dtype='float32')    \n",
    "    y = LogMelSpectrogram(sample_rate, fft_size, hop_size, n_mels, fmin, fmax)(x)\n",
    "    y = BatchNormalization(axis=2)(y)\n",
    "\n",
    "\n",
    "    y = Conv2D(3, (3,3), padding='same')(y)  \n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = trained_vgg(y, training=False)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = Dense(1024, activation='relu')(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    y = Dense(512, activation='relu')(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    \n",
    "    y = Dense(n_classes, activation='softmax')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7912,
     "status": "ok",
     "timestamp": 1599825492066,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "4ud9q744wlJr",
    "outputId": "78cc93af-a36e-49d4-ff65-b0c7dc25e3f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 900000)]          0         \n",
      "_________________________________________________________________\n",
      "log_mel_spectrogram (LogMelS (None, 1756, 128, 1)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1756, 128, 1)      512       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1756, 128, 3)      30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1756, 128, 3)      12        \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 110592)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              113247232 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 264)               135432    \n",
      "=================================================================\n",
      "Total params: 128,622,706\n",
      "Trainable params: 128,622,444\n",
      "Non-trainable params: 262\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, schedules\n",
    "\n",
    "n_classes = N_CLASSES\n",
    "# model = ConvModel(n_classes)\n",
    "\n",
    "# lr_schedule = schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.05, decay_steps=1000, decay_rate=0.96, staircase=False\n",
    "# )\n",
    "# sgd = SGD(learning_rate=lr_schedule, momentum=0.85)\n",
    "# model.compile(optimizer='sgd',\n",
    "#               loss='sparse_categorical_crossentropy', \n",
    "#               metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model = tf.keras.models.load_model('Model-6')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1600059089482,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "N4qAfovmwnno",
    "outputId": "75f7cb7d-2a70-40a1-d608-d2a5311c89fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1781"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train)//12\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 947
    },
    "colab_type": "code",
    "id": "oVj2nvCtx5oq",
    "outputId": "88b92b77-1881-46c2-e56d-9423ab44264a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.9439 - sparse_categorical_accuracy: 0.7508\n",
      "Epoch 00001: val_loss improved from inf to 4.00168, saving model to /content/drive/My Drive/Bird/VGG/VGG-one-cont\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one-cont/assets\n",
      "5343/5343 [==============================] - 3574s 669ms/step - loss: 0.9439 - sparse_categorical_accuracy: 0.7508 - val_loss: 4.0017 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.6501 - sparse_categorical_accuracy: 0.8232\n",
      "Epoch 00002: val_loss did not improve from 4.00168\n",
      "5343/5343 [==============================] - 3331s 624ms/step - loss: 0.6501 - sparse_categorical_accuracy: 0.8232 - val_loss: 5.7729 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.4747 - sparse_categorical_accuracy: 0.8723\n",
      "Epoch 00003: val_loss did not improve from 4.00168\n",
      "5343/5343 [==============================] - 3177s 595ms/step - loss: 0.4747 - sparse_categorical_accuracy: 0.8723 - val_loss: 4.1920 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.3521 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 00004: val_loss did not improve from 4.00168\n",
      "5343/5343 [==============================] - 3168s 593ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.9024 - val_loss: 4.4697 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 5/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.2822 - sparse_categorical_accuracy: 0.9252\n",
      "Epoch 00005: val_loss did not improve from 4.00168\n",
      "5343/5343 [==============================] - 3201s 599ms/step - loss: 0.2822 - sparse_categorical_accuracy: 0.9252 - val_loss: 6.8543 - val_sparse_categorical_accuracy: 0.0833\n",
      "Epoch 6/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.2157 - sparse_categorical_accuracy: 0.9402\n",
      "Epoch 00006: val_loss improved from 4.00168 to 3.54673, saving model to /content/drive/My Drive/Bird/VGG/VGG-one-cont\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/Bird/VGG/VGG-one-cont/assets\n",
      "5343/5343 [==============================] - 3190s 597ms/step - loss: 0.2157 - sparse_categorical_accuracy: 0.9402 - val_loss: 3.5467 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 7/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.1788 - sparse_categorical_accuracy: 0.9507\n",
      "Epoch 00007: val_loss did not improve from 3.54673\n",
      "5343/5343 [==============================] - 3194s 598ms/step - loss: 0.1788 - sparse_categorical_accuracy: 0.9507 - val_loss: 4.0501 - val_sparse_categorical_accuracy: 0.4167\n",
      "Epoch 8/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.1725 - sparse_categorical_accuracy: 0.9530\n",
      "Epoch 00008: val_loss did not improve from 3.54673\n",
      "5343/5343 [==============================] - 3191s 597ms/step - loss: 0.1725 - sparse_categorical_accuracy: 0.9530 - val_loss: 5.3216 - val_sparse_categorical_accuracy: 0.1667\n",
      "Epoch 9/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.1524 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 00009: val_loss did not improve from 3.54673\n",
      "5343/5343 [==============================] - 2881s 539ms/step - loss: 0.1524 - sparse_categorical_accuracy: 0.9588 - val_loss: 6.7897 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 10/20\n",
      "5343/5343 [==============================] - ETA: 0s - loss: 0.1084 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 00010: val_loss did not improve from 3.54673\n",
      "5343/5343 [==============================] - 3204s 600ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9698 - val_loss: 4.7299 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 11/20\n",
      " 738/5343 [===>..........................] - ETA: 39:54 - loss: 0.1086 - sparse_categorical_accuracy: 0.9713Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = 'Model-6-continued'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    verbose=2)\n",
    "\n",
    "model.fit(train_final, \n",
    "          epochs=20, \n",
    "          steps_per_epoch=steps_per_epoch, \n",
    "          validation_data=test_final, \n",
    "          validation_steps=2, \n",
    "         callbacks=[model_checkpoint_callback])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmGdMkg2BswWNt6MmJr2RH",
   "mount_file_id": "1-voi8xrhHzo7T5-r4xcOZvlPlzp8tivu",
   "name": "Copy of VGG.ipynb",
   "provenance": [
    {
     "file_id": "1CfPHjtRcy71w29djt8g8Hsq1G81BXeon",
     "timestamp": 1599824540803
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
