{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1938,
     "status": "ok",
     "timestamp": 1598771263584,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "UnajK5UNg2oP"
   },
   "outputs": [],
   "source": [
    "# each TF-Record file is for a single class and will be loaded into a separate tf.data.Dataset\n",
    "# these datasets will be appended to a list, and fed into tf.experimental.sample_from_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4334,
     "status": "ok",
     "timestamp": 1598771265987,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "1CydPQMnh3ac"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pathlib\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4330,
     "status": "ok",
     "timestamp": 1598771265988,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "QRfgh98I3eUZ"
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 264 \n",
    "SAMPLE_RATE = 30000 # Audio sample rate\n",
    "MAX_DURATION = 30 # Clip duration in seconds \n",
    "FFT_SIZE = 1024 # Fourier Transform size \n",
    "HOP_SIZE = 512 # Number of samples between each successive FFT window\n",
    "N_MEL_BINS = 128 \n",
    "N_SPECTROGRAM_BINS = (FFT_SIZE // 2) + 1\n",
    "F_MIN = 20 # Min frequency cutoff\n",
    "F_MAX = SAMPLE_RATE / 2  # Max Frequency cutoff\n",
    "BATCH_SIZE = 4  # Training Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4326,
     "status": "ok",
     "timestamp": 1598771265988,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "cYJdCaKEFRlc"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/content/drive/My Drive/train.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4323,
     "status": "ok",
     "timestamp": 1598771265989,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "O9czwVPJOKTN"
   },
   "outputs": [],
   "source": [
    "# directories for Train and Test TF Records, 264 files in each\n",
    "train_dir = '/content/drive/My Drive/lala1/Data/Train'\n",
    "test_dir = '/content/drive/My Drive/lala1/Data/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook uses 30 seconds worth of data at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4319,
     "status": "ok",
     "timestamp": 1598771265989,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "hzz6t3TfhTYV"
   },
   "outputs": [],
   "source": [
    "train_tfr = os.listdir(train_dir)\n",
    "test_tfr = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4316,
     "status": "ok",
     "timestamp": 1598771265990,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "gIQteKtFhk8A"
   },
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "          'feature0': tf.io.FixedLenFeature((), tf.string),\n",
    "          'feature1': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "\n",
    "    feature0 = tf.io.parse_tensor(example['feature0'], out_type = tf.float32)\n",
    "    feature1 = example['feature1']\n",
    "\n",
    "    return feature0, feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9036,
     "status": "ok",
     "timestamp": 1598771270725,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "66NKzhqchsSL"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "lis = [0]*264\n",
    "for d in train_tfr:\n",
    "    d_path = os.path.join(train_dir, d)\n",
    "    tfrecord_dataset_train = tf.data.TFRecordDataset([d_path], compression_type=\"GZIP\")\n",
    "    dataset = tfrecord_dataset_train.map(read_tfrecord)\n",
    "    lis[i] = dataset\n",
    "    i = i+1\n",
    "\n",
    "train_ds = tf.data.experimental.sample_from_datasets(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9031,
     "status": "ok",
     "timestamp": 1598771270727,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "_terMwZpOZah",
    "outputId": "4d99753a-4e86-45a8-eef1-c1526b3ccc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "print(i) #264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12826,
     "status": "ok",
     "timestamp": 1598771274531,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "trgNh8APig7s"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "lis = [0]*264\n",
    "for d in test_tfr:\n",
    "    d_path = os.path.join(test_dir, d)\n",
    "    tfrecord_dataset_test = tf.data.TFRecordDataset([d_path], compression_type=\"GZIP\")\n",
    "    dataset = tfrecord_dataset_test.map(read_tfrecord)\n",
    "    lis[i] = dataset\n",
    "    i = i+1\n",
    "\n",
    "test_ds = tf.data.experimental.sample_from_datasets(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12821,
     "status": "ok",
     "timestamp": 1598771274532,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "7JW3BYuANfri",
    "outputId": "c7d02c9f-0c93-4c5d-a3e9-be198dc4992d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "print(i) #264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12813,
     "status": "ok",
     "timestamp": 1598771274533,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "TDhK_drviwyL"
   },
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, shuffle_buffer_size=64, batch_size=4):\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.batch(batch_size).repeat()\n",
    "    ds = ds.map(setshape)\n",
    "    ds = ds.prefetch(5)\n",
    "    return ds\n",
    "\n",
    "def setshape(x, y):\n",
    "    x.set_shape([None, 900000,1])\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y.set_shape([None,1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12810,
     "status": "ok",
     "timestamp": 1598771274534,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "ymrkwibnizvX"
   },
   "outputs": [],
   "source": [
    "train_final = prepare_for_training(train_ds)\n",
    "test_final = prepare_for_training(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding tensors to a layer which calculated the Mel Spectrogram for the given audio instance\n",
    "# this in turn is treated like an image, and 2D convolutions are applied, and sent to a trained Resnet\n",
    "# the Resnet weights are frozen, and is only used to extract features from the Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12803,
     "status": "ok",
     "timestamp": 1598771274534,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "NuXW0ZEkEnIL"
   },
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14671,
     "status": "ok",
     "timestamp": 1598771276407,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "7DztZDKZErDQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(311, 128, 3))\n",
    "\n",
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14668,
     "status": "ok",
     "timestamp": 1598771276409,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "l3Ox4Wh1E0p3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D)\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def ConvModel(n_classes, sample_rate=SAMPLE_RATE, duration=MAX_DURATION,\n",
    "              fft_size=FFT_SIZE, hop_size=HOP_SIZE, n_mels=N_MEL_BINS, fmin=F_MIN, fmax=F_MAX):\n",
    "    n_samples = sample_rate * duration\n",
    "    input_shape = (n_samples,)\n",
    "\n",
    "    x = Input(shape=input_shape, name='input', dtype='float32')    \n",
    "    y = LogMelSpectrogram(sample_rate, fft_size, hop_size, n_mels, fmin, fmax)(x)\n",
    "    y = BatchNormalization(axis=2)(y)\n",
    "\n",
    "\n",
    "    y = Conv2D(3, (3,3), padding='same')(y)  \n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    y = feature_extractor_layer(y, training=False)\n",
    "\n",
    "    y = Dense(1024, activation='relu')(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    y = Dense(1024, activation='relu')(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    \n",
    "    y = Dense(n_classes, activation='softmax')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15387,
     "status": "ok",
     "timestamp": 1598771277133,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "sU_6VQUAE9hT",
    "outputId": "7d039d49-2f0a-414c-c3a9-be76989f3689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 900000)]          0         \n",
      "_________________________________________________________________\n",
      "log_mel_spectrogram (LogMelS (None, 1756, 128, 1)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1756, 128, 1)      512       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1756, 128, 3)      30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1756, 128, 3)      12        \n",
      "_________________________________________________________________\n",
      "keras_layer (KerasLayer)     (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 264)               270600    \n",
      "=================================================================\n",
      "Total params: 26,983,730\n",
      "Trainable params: 3,418,668\n",
      "Non-trainable params: 23,565,062\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, schedules\n",
    "\n",
    "n_classes = N_CLASSES\n",
    "model = ConvModel(n_classes)\n",
    "\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.05, decay_steps=1000, decay_rate=0.96, staircase=False\n",
    ")\n",
    "sgd = SGD(learning_rate=lr_schedule, momentum=0.85)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15379,
     "status": "ok",
     "timestamp": 1598771277134,
     "user": {
      "displayName": "ShambSar",
      "photoUrl": "",
      "userId": "01685406212133283221"
     },
     "user_tz": -330
    },
    "id": "2UrHXJ8fFFmT",
    "outputId": "251cfc79-80f6-4688-c667-e0940db6aaf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5343"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train)//BATCH_SIZE\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "KYFQMbOvF8-O",
    "outputId": "272f4782-724a-4424-b02c-8bec6b2ad0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5343/5343 [==============================] - ETA: 0s - loss: nan - sparse_categorical_accuracy: 0.0057WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "5343/5343 [==============================] - 40287s 8s/step - loss: nan - sparse_categorical_accuracy: 0.0057 - val_loss: nan - val_sparse_categorical_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      " 309/5343 [>.............................] - ETA: 10:25:26 - loss: nan - sparse_categorical_accuracy: 0.0040"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = 'Model-3'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model.fit(train_final, \n",
    "          epochs=50, \n",
    "          steps_per_epoch=steps_per_epoch, \n",
    "          validation_data=test_final, \n",
    "          validation_steps=2, \n",
    "         callbacks=[model_checkpoint_callback, early_stop])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEBFj9HFDQgFREn0H9ar0q",
   "collapsed_sections": [],
   "mount_file_id": "1q35_3CNspVmPhRYRAt9bhen4tzxjMSkk",
   "name": "Model-Mel-1.ipynb",
   "provenance": [
    {
     "file_id": "1LmlvpPSOxqcrLlZD011xruurhcRCyfs2",
     "timestamp": 1598698570967
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
